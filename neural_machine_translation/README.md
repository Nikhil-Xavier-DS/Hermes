# Natural Machine Translation

Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model.

The basic idea behind Sequence to Sequence Model is the encoder-decoder architecture. These networks are usually used for a variety of tasks like text-summerization, Machine translation, Image Captioning, etc.

Some of the popular neural machine translation algorithms implemented in Hermes are explained in brief below.

### [Neural Machine Translation](https://github.com/Nikhil-Xavier-DS/Hermes/tree/master/neural_machine_translation)
>* RNN based Encoder-Decoder Seq-Seq Model
>* Bidirectional RNN based Encoder-Decoder Seq-Seq Model
>* GRU based Encoder-Decoder Seq-Seq Model
>* Bidirectional GRU based Encoder-Decoder Seq-Seq Model
>* LSTM based Encoder-Decoder Seq-Seq Model
>* Bidirectional LSTM based Encoder-Decoder Seq-Seq Model
> ##### Dataset to be added


#### Reference
1. https://www.tensorflow.org
2. https://github.com/yvchen/JointSLU/tree/master/data